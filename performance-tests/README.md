# ğŸš€ Pruebas de Performance - MediSupply

Pruebas de performance end-to-end contra el edge-proxy de producciÃ³n.

## ğŸ“Š Ãšltima EjecuciÃ³n

**Fecha**: 25 de Noviembre de 2025  
**Resultados**: Ver [PERFORMANCE_TEST_RESULTS_FINAL.md](./PERFORMANCE_TEST_RESULTS_FINAL.md) â­  
**Status**: âœ… **EXITOSO** - 7 de 9 tests pasaron | Todos los SLAs cumplidos  
**Tiempo Promedio**: 315ms | **Rating**: â­â­â­â­â­

## ğŸ“‹ SLAs a Validar

| MÃ©trica | Objetivo | Test |
|---------|----------|------|
| **LocalizaciÃ³n** | â‰¤1s | Bodegas, VehÃ­culos |
| **OptimizaciÃ³n de Rutas** | â‰¤3s | CÃ¡lculo de ruta Ã³ptima |
| **Throughput de Ã“rdenes** | 100-400 pedidos/min | CreaciÃ³n masiva de Ã³rdenes |
| **Endpoints Generales** | â‰¤2s | Lista productos, clientes, etc. |

## ğŸ”§ InstalaciÃ³n

```bash
cd performance-tests

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸ§ª Tipos de Pruebas

### 1. **Response Time Tests** (pytest-benchmark)

Miden el tiempo de respuesta de endpoints individuales.

```bash
# Ejecutar todas las pruebas de tiempo de respuesta
pytest test_response_time.py -v

# Con reporte detallado de benchmark
pytest test_response_time.py -v --benchmark-only

# Guardar resultados en JSON
pytest test_response_time.py --benchmark-json=results.json

# Ver comparaciones entre ejecuciones
pytest-benchmark compare results.json
```

**Ejemplo de salida:**
```
test_login_performance                  PASSED (mean: 0.235s, max: 0.421s) âœ…
test_list_bodegas_performance          PASSED (mean: 0.512s, max: 0.892s) âœ… SLA â‰¤1s
test_route_optimization_performance    PASSED (mean: 2.145s, max: 2.987s) âœ… SLA â‰¤3s
```

### 2. **Load Tests** (Locust)

Simulan carga de mÃºltiples usuarios concurrentes.

#### Modo Interactivo (con UI web)

```bash
locust -f locustfile.py --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app
```

Abre http://localhost:8089 y configura:
- **Number of users**: 10
- **Spawn rate**: 2 users/second
- **Run time**: 1m

#### Modo Headless (sin UI)

```bash
# Test rÃ¡pido: 10 usuarios, 1 minuto
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 10 --spawn-rate 2 --run-time 1m --headless

# Test de carga media: 50 usuarios, 5 minutos
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 50 --spawn-rate 5 --run-time 5m --headless

# Test de carga alta: 100 usuarios, 10 minutos
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 100 --spawn-rate 10 --run-time 10m --headless
```

#### Test especÃ­fico de Throughput de Ã“rdenes

```bash
# Medir creaciÃ³n de Ã³rdenes (SLA: 100-400/min)
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 20 --spawn-rate 5 --run-time 2m --headless \
  OrderCreationUser
```

**Ejemplo de salida:**
```
======================================================================
ğŸ“Š RESULTADOS DE PERFORMANCE
======================================================================
â±ï¸  Tiempo de ejecuciÃ³n: 120.45s (2.01 min)
ğŸ“¦ Ã“rdenes creadas: 456
ğŸš€ Throughput: 227.11 Ã³rdenes/minuto
----------------------------------------------------------------------
âœ… SLA CUMPLIDO: 227.11 estÃ¡ dentro del rango 100-400 Ã³rdenes/min
======================================================================
```

## ğŸ“Š Estructura de Archivos

```
performance-tests/
â”œâ”€â”€ config.py                # ConfiguraciÃ³n (URLs, SLAs, credenciales)
â”œâ”€â”€ conftest.py             # Fixtures de pytest
â”œâ”€â”€ test_response_time.py   # Tests de tiempo de respuesta (benchmark)
â”œâ”€â”€ locustfile.py           # Tests de carga (Locust)
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md              # Esta documentaciÃ³n
```

## ğŸ¯ Clases de Usuario en Locust

### `MediSupplyUser`
Usuario general que realiza operaciones comunes:
- Listar productos (peso: 3)
- Listar clientes (peso: 2)
- Listar Ã³rdenes (peso: 2)
- Listar vendedores (peso: 1)
- LocalizaciÃ³n de bodegas/vehÃ­culos (peso: 1)

### `OrderCreationUser`
Usuario especializado en crear Ã³rdenes para medir throughput:
- Crear Ã³rdenes continuamente (peso: 10)
- Objetivo: 100-400 Ã³rdenes/minuto

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### pytest-benchmark

```python
stats.mean    # Tiempo promedio de respuesta
stats.max     # Tiempo mÃ¡ximo (peor caso)
stats.min     # Tiempo mÃ­nimo (mejor caso)
stats.stddev  # DesviaciÃ³n estÃ¡ndar
```

### Locust

```
Request/s    # Requests por segundo
Failures     # Requests fallidos
Average (ms) # Tiempo de respuesta promedio
Min (ms)     # Tiempo mÃ­nimo
Max (ms)     # Tiempo mÃ¡ximo
```

## ğŸš¨ Criterios de Ã‰xito

### Response Time Tests
- âœ… **LocalizaciÃ³n**: Mean < 1.0s, Max < 1.5s
- âœ… **Rutas**: Mean < 3.0s, Max < 4.5s
- âœ… **Endpoints generales**: Mean < 2.0s, Max < 3.0s

### Load Tests
- âœ… **Error rate**: < 1%
- âœ… **Response time 95th percentile**: < 3s
- âœ… **Throughput Ã³rdenes**: 100-400/min

## ğŸ” Troubleshooting

### Error: "No se pudo obtener token de autenticaciÃ³n"
Verifica las credenciales en `config.py` o variables de entorno.

### Error: 404 en endpoints
Verifica que el edge-proxy estÃ© desplegado y accesible.

### Performance degradada
1. Verifica la carga actual del sistema
2. Revisa logs del edge-proxy y microservicios
3. Considera escalar los recursos (HPA en Kubernetes)

## ğŸ“ Ejemplo de EjecuciÃ³n Completa

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Ejecutar tests de tiempo de respuesta
pytest test_response_time.py -v --benchmark-only

# 3. Ejecutar test de carga ligera
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 10 --spawn-rate 2 --run-time 2m --headless

# 4. Ejecutar test de throughput de Ã³rdenes
locust -f locustfile.py \
  --host=https://medisupply-edge-proxy-n5jhaxtfma-uc.a.run.app \
  --users 20 --spawn-rate 5 --run-time 2m --headless \
  OrderCreationUser
```

## ğŸ”„ IntegraciÃ³n con CI/CD

Agregar al pipeline:

```yaml
performance-tests:
  stage: test
  script:
    - cd performance-tests
    - pip install -r requirements.txt
    - pytest test_response_time.py --benchmark-only --benchmark-json=results.json
    - locust -f locustfile.py --host=$EDGE_PROXY_URL --users 10 --spawn-rate 2 --run-time 1m --headless
  artifacts:
    paths:
      - performance-tests/results.json
```

## ğŸ“š Referencias

- [pytest-benchmark docs](https://pytest-benchmark.readthedocs.io/)
- [Locust docs](https://docs.locust.io/)
- [Plan de Pruebas MediSupply - SecciÃ³n 2.4.3 (Performance)](../docs/test-plan.md)

